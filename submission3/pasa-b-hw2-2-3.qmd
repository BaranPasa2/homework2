---
title: "Homework 2 - Submission 3"
subtitle: "ECON 470"
author: "Baran Pasa"
execute:
  echo: false
format:
  pdf:
    output-file: "pasa-b-hwk2-3"
    output-exit: "pdf"
    code-fold: true
    highlight-style: github
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}

jupyter: python3

---

# Homework 2 Analysis 

###### [Link to Github](https://github.com/BaranPasa2/homework2)

### Part 0: Importing and cleaning the data

The data was cleaned in order to make summarizing and analysis easier. My cleaning process relied heavily on the code kindly provided to us by our TA Pablo. Additinally, data was only used from 2008 to 2015 due to my computer's lack of power.

### Part 1 Summarizing the Data
The graphs on the next page provide a small summary of the data. Violin plots were used in order to display the general distribution of the data for each given year, providing better insights into the data. As the violin plots show distributions, I took the log of the data so that while the shape was maintained, outliers did not distort the graphs and hinder interpretation. 
```{python}
exec(open("/Users/baranpasa/Library/Mobile Documents/com~apple~CloudDocs/Desktop/Emory/Junior Year/Junior Spring/ECON 470/ECON 470 Python /homework2/submission3/data_summary_v3.py").read())
```

As you can see, only the years 2008 through 2014 are visible. You can also see that there is distribution of NaN on the final graph. This is an issue that needs to be furhter addressed, and is most likely occuring to due to faulty code. 


### Part 2: Estimating ATE

For the rest of the assignment, we are only working within the year 2012.
```{python}
#| echo: false
#| warning: false
#| message: false
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from causalinference import CausalModel 
import markdown
import pandas as pd
import numpy as np
from IPython.display import display, Markdown
```

#### Question 5
First we begin by penalizing the hospitals that have a negative HRRP and HBVP sum and calculate their respective mean price:


```{python}
#| echo: false
#| warning: false
#| message: false
HCRIS = pd.read_csv('/Users/baranpasa/Library/Mobile Documents/com~apple~CloudDocs/Desktop/Emory/Junior Year/Junior Spring/ECON 470/ECON 470 Python /homework2/submission3/data/output/HCRIS_Data.csv')
#from data_summary_v3 import HCRIS_data_filtered as HCRIS_data

hcris_2012 = HCRIS[HCRIS['year'] == 2012]

#Calculating estimated price for 2012
hcris_2012['discount_factor'] = 1 - hcris_2012['tot_discounts'] / hcris_2012['tot_charges']
hcris_2012['price_num'] = (
    (hcris_2012['ip_charges'] + hcris_2012['icu_charges'] + hcris_2012['ancillary_charges'])
    * hcris_2012['discount_factor'] - hcris_2012['tot_mcare_payment'])
hcris_2012['price_denom'] = hcris_2012['tot_discharges'] - hcris_2012['mcare_discharges']
hcris_2012['price'] = hcris_2012['price_num'] / hcris_2012['price_denom']

# Cleaning the  data
hcris_2012 = hcris_2012[(hcris_2012['price_denom'] > 100) & (hcris_2012['price_num'] > 0) & (hcris_2012['price'] > 0)]
hcris_2012 = hcris_2012[hcris_2012['beds'] > 30]
hcris_2012 = hcris_2012[hcris_2012['price'] < 100000]  

#NA payments
hcris_2012['hvbp_payment'] = hcris_2012['hvbp_payment'].fillna(0)
hcris_2012['hrrp_payment'] = hcris_2012['hrrp_payment'].fillna(0).abs()

#Defining penalty 
hcris_2012['penalty'] = (hcris_2012['hvbp_payment'] + hcris_2012['hrrp_payment'] < 0).astype(int)


# Calculate average price for penalized vs non-penalized hospitals
mean_penalized = round(hcris_2012.loc[hcris_2012['penalty'] == 1, 'price'].mean(), 2)
mean_non_penalized = round(hcris_2012.loc[hcris_2012['penalty'] == 0, 'price'].mean(), 2)

print(f"Average price for penalized hospitals in 2012: {mean_penalized}")
print(f"Average price for non-penalized hospitals in 2012: {mean_non_penalized}")


```
As you can see, non-penalized hospitals have a lower mean price than penalized hospitals.

#### Question 6
We then sort all hospitals into 4 quartiles based on the number of beds provided.
```{python}
#| echo: false
#| warning: false
#| message: false
hcris_2012['beds_quartile'] = pd.qcut(hcris_2012['beds'], 4, labels=[1, 2, 3, 4])

# Create indicator variables for each quartile
for i in range(1, 5):
    hcris_2012[f'quartile_{i}'] = (hcris_2012['beds_quartile'] == i).astype(int)


# Calculate average price for treated and control groups within each quartile
Avg_per_group = []
for i in range(1, 5):
    treated_mean = hcris_2012.loc[(hcris_2012[f'quartile_{i}'] == 1) & (hcris_2012['penalty'] == 1), 'price'].mean()
    control_mean = hcris_2012.loc[(hcris_2012[f'quartile_{i}'] == 1) & (hcris_2012['penalty'] == 0), 'price'].mean()
    Avg_per_group.append({'Quartile': i, 'Penalized_Mean_Price': round(treated_mean, 2), 'Non_penalized_Mean_Price': round(control_mean, 2)})

bed_quart_table = pd.DataFrame(Avg_per_group)
#print(bed_quart_table.to_string(index=False))
display(Markdown(bed_quart_table.to_markdown(index=False)))
```

As shown above, penalized hospitals have a higher mean price across all quartiles.

#### Quesiton 7:
Now we run a regression 4 times, using 4 different regression models, and compare the results.

```{python}
#| echo: false
#| warning: false
#| message: false
hcris_2012['bed_quartile'] = pd.qcut(hcris_2012['beds'], 4, labels=False)
bed_quart_dummies = pd.get_dummies(hcris_2012['bed_quartile'], prefix='bed_quart').iloc[:, :-1] * 1
bed_quart_dummies = bed_quart_dummies.sub(bed_quart_dummies.mean(axis=0), axis=1)

Y = hcris_2012['price'].values
D = hcris_2012['penalty'].values
X = bed_quart_dummies.values

reg_results = pd.DataFrame(index=['ATE', 'SE'], columns=['INV', 'MAH', 'IPW', 'OLS'])
cm = CausalModel(Y=Y, D=D, X=X)

cm.est_via_matching(weights='inv', matches=1, bias_adj=True)
inv_ate = cm.estimates['matching']['ate']
inv_se = cm.estimates['matching']['ate_se']
reg_results.loc['ATE', 'INV'] = inv_ate
reg_results.loc['SE', 'INV'] = inv_se

cm.est_via_matching(weights='maha', matches=1, bias_adj=True)
reg_results.loc['ATE', 'MAH'] = cm.estimates['matching']['ate'] 
reg_results.loc['SE', 'MAH'] = cm.estimates['matching']['ate_se']

cm.est_propensity()
cm.est_via_weighting()
reg_results.loc['ATE', 'IPW'] = cm.estimates['weighting']['ate']
reg_results.loc['SE', 'IPW'] = cm.estimates['weighting']['ate_se']

cm.est_via_ols(adj=2)
reg_results.loc['ATE', 'OLS'] = cm.estimates['ols']['ate']
reg_results.loc['SE', 'OLS'] = cm.estimates['ols']['ate_se']

reg_results = reg_results.astype(float).round(2)
#print(reg_results)
display(Markdown(reg_results.to_markdown()))
```

#### Question 8

Across all four regressions, the results are identical, but the standard errors are different. The standard error variance makes sense, as each regression method handles clutering and correlation in a data differently, and also assigns different weights while regressing. 

\newpage

#### Question 9
I do not believe that I accuratly estimated causal effect of the penalty. There are many more variables that impact prices that must be taken into account, such as the amount paid to physicians, the CoL for the area in which the hospital resides, etc. Such a simple regression is not able to establish a causal effect of the penalty on hospital pricing.

#### Question 10
Working with this data was quite the struggle. It took me a long time to clean the data properly, and for hours I was not able to get any values for neither payment types. Almost everything aggrivated me at some point, but few things are as rewarding as when everything clicks and my code runs and outputs a clean results. Moving forward, I need to pay much closer attention to how my code cleans the data, so that I do not struggle like I did here. 